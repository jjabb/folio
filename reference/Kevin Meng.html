<!DOCTYPE html>
<!-- saved from url=(0017)https://mengk.me/ -->
<html id="html" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>Kevin Meng</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta
      name="description"
      content="I&#39;m a student at MIT. I enjoy tinkering with software, neural nets, and a bunch of other things."
    />
    <meta
      name="keywords"
      content="Kevin Meng, Kevin, Meng, Computer Science, Artificial Intelligence, MIT, Deep Learning"
    />
    <meta name="author" content="Kevin Meng" />
    <link href="./Kevin Meng_files/css2" rel="stylesheet" />
    <link rel="stylesheet" href="./Kevin Meng_files/main.css" />
    <link rel="stylesheet" href="./Kevin Meng_files/timeline.css" />
    <link rel="stylesheet" href="./Kevin Meng_files/font-awesome.min.css" />
    <link
      rel="stylesheet"
      href="./Kevin Meng_files/bootstrap.min.css"
      integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm"
      crossorigin="anonymous"
    />
    <link rel="stylesheet" href="./Kevin Meng_files/academicons.min.css" />
    <link rel="shortcut icon" href="https://mengk.me/mit.ico" />

    <script async="" src="./Kevin Meng_files/js"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-403EXC4N6Y");
    </script>
  </head>
  <body id="top">
    <nav
      id="navbar"
      class="navbar navbar-fixed-top navbar-expand-lg navbar-light bg-info sticky-top mb-4"
    >
      <a class="navbar-brand" href="https://mengk.me/#" style="color: white"
        >Kevin Meng</a
      >
      <button
        class="navbar-toggler"
        type="button"
        data-toggle="collapse"
        data-target="#navbarSupportedContent"
        aria-controls="navbarSupportedContent"
        aria-expanded="false"
        aria-label="Toggle navigation"
      >
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a
              class="nav-link"
              href="https://mengk.me/#top"
              style="color: white"
              >home</a
            >
          </li>
          <li class="nav-item">
            <a
              class="nav-link"
              href="https://mengk.me/#about"
              style="color: white"
              >about</a
            >
          </li>

          <li class="nav-item">
            <a
              class="nav-link"
              href="https://mengk.me/#projects"
              style="color: white"
              >projects</a
            >
          </li>

          <li class="nav-item">
            <a
              class="nav-link"
              href="https://mengk.me/assets/pdfs/resume.pdf"
              style="color: white"
              target="_blank"
              >resume</a
            >
          </li>
        </ul>
      </div>
    </nav>

    <div id="home" class="container mb-4">
      <div class="row justify-content-center">
        <div class="col-md-3 my-auto" align="center">
          <div class="w-75" style="overflow: hidden; border-radius: 50%">
            <img
              class="img-fluid"
              src="./Kevin Meng_files/mengkme_full.jpg"
              alt="Kevin&#39;s picture"
            />
          </div>
        </div>
        <div class="col-md-4 my-auto py-2">
          <h1 class="sect-header">Kevin Meng</h1>

          <p class="my-0">
            currently: @<a href="https://web.mit.edu/" target="_blank">mit</a>
            @<a href="https://csail.mit.edu/" target="_blank">csail</a> @<a
              href="https://www.northeastern.edu/"
              target="_blank"
              >neu</a
            >
          </p>

          <p class="my-0">
            contact:
            <a
              href="https://www.youtube.com/watch?v=QPX9b3Vtz0I"
              target="_blank"
              >mengk at mit dot edu</a
            >
          </p>
          <p>where i am: cambridge, ma</p>
          <p>
            <a
              href="https://www.facebook.com/kmeng01/"
              target="_blank"
              class="fa fa-facebook"
            ></a>
            <a
              href="https://twitter.com/mengk20"
              target="_blank"
              class="fa fa-twitter"
            ></a>
            <a
              href="https://www.linkedin.com/in/kmeng01/"
              target="_blank"
              class="fa fa-linkedin"
            ></a>
            <a
              href="https://www.youtube.com/channel/UCkSH0dNQk7BQcCPVUMfZCqA"
              target="_blank"
              class="fa fa-youtube"
            ></a>
            <a
              href="https://www.instagram.com/kmeng01/"
              target="_blank"
              class="fa fa-instagram"
            ></a>
            <a
              href="https://www.github.com/kmeng01/"
              target="_blank"
              class="fa fa-github"
            ></a>
            <a
              href="https://www.semanticscholar.org/author/153615419"
              target="_blank"
              class="fa ai ai-google-scholar"
            ></a>
          </p>
        </div>
        <div class="col-md-3 my-auto">
          <h4 class="mb-2">my interests:</h4>
          <ul>
            <li>interpretability</li>
            <li>search engines</li>
            <li>protein &amp; drug design</li>
            <li>robotic planning</li>
          </ul>
        </div>
      </div>
    </div>
    <div id="about" class="container mb-2">
      <div class="row">
        <div class="col-md-12">
          <h2 class="sect-header">about me.</h2>
          <p style="text-align: justify">
            Hi! 👋 I'm Kevin, an undergrad at MIT studying EECS and pursuing a
            concurrent master's in AI. I spend lots of time thinking about
            <a href="https://mengk.me/#rome"
              >transparency in deep neural networks</a
            >, search algorithms, and probabilistic models. Aside from work and
            research, I also care deeply about teaching. Back at home, I ran
            <a target="_blank" href="https://www.aysi.org/">a non-profit</a>
            providing personalized research and
            <a
              target="_blank"
              href="https://mengk.me/assets/pdfs/aysi/aysi-sci-20.pdf"
              >mentorship</a
            >
            to aspiring scientists, where I still occasionally volunteer. At
            MIT, I organize and teach for
            <a target="_blank" href="https://aiclub.mit.edu/"
              >AI@MIT Workshops</a
            >
            and have taught for
            <a
              href="https://esp.mit.edu/learn/Splash/index.html"
              target="_blank"
              >Splash</a
            >.
          </p>
          <p>
            In my free time, I enjoy cooking, reading,
            <a href="https://www.strava.com/athletes/kmeng01" target="_blank"
              >running</a
            >, playing card games, taking road trips, being trash at basketball,
            and wandering the streets of new cities. I used to make music and
            miss it a lot.
          </p>
        </div>
      </div>
    </div>
    <div id="news" class="container mb-2">
      <div class="row">
        <div class="col-md-12">
          <h2 class="sect-header">recent news.</h2>
          <div class="container">
            <div class="row">
              <div class="col-md-12">
                <ul class="timeline">
                  <li>
                    <b>jan 2023</b><br />
                    <a href="https://mengk.me/#memit">MEMIT</a> was accepted to
                    <a
                      href="https://en.wikipedia.org/wiki/International_Conference_on_Learning_Representations"
                      target="_blank"
                      >ICLR '23</a
                    >! We've scaled ROME to 100x state-of-the-art model editors
                    [<a
                      href="https://twitter.com/mengk20/status/1588581237345595394"
                      target="_blank"
                      >twitter</a
                    >]
                  </li>
                  <li>
                    <b>sept 2022</b><br />
                    <a href="https://mengk.me/#rome">ROME</a> will appear in
                    <a
                      href="https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems"
                      target="_blank"
                      >NeurIPS '22</a
                    >! [<a
                      href="https://twitter.com/mengk20/status/1588581237345595394"
                      target="_blank"
                      >twitter</a
                    >]
                  </li>

                  <li>
                    <b>february 2022</b><br />
                    We've released <a href="https://mengk.me/#rome">ROME</a>, a
                    study on the fact-storing mechanisms in large
                    auto-regressive transformer language models [<a
                      href="https://twitter.com/ak92501/status/1491950768416514062"
                      target="_blank"
                      >twitter</a
                    >]
                  </li>
                  <li>
                    <b>October 2020</b><br />
                    Our
                    <a href="https://mengk.me/#gbat">ClaimBuster model</a> is
                    being used by the Duke Reporter's Lab to help fact-check the
                    2020 Presidential Election [<a
                      href="https://www.poynter.org/fact-checking/2020/how-the-duke-reporters-lab-used-the-political-conventions-to-perfect-its-automated-fact-checking-program/"
                      target="_blank"
                      >poynter</a
                    >]
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div id="projects" class="container mb-2">
      <div class="row">
        <div class="col-md-12">
          <h2 class="sect-header">things i've worked on.</h2>
          <div id="memit" class="row mb-3">
            <div class="col-md-8">
              <h5 style="font-weight: bold">
                Mass-Editing a Transformer Memory
              </h5>
              <p>
                <a
                  class="box-in paper"
                  target="_blank"
                  href="https://arxiv.org/abs/2210.07229"
                  >ICLR '23</a
                >
                |
                <a
                  class="box-in code"
                  target="_blank"
                  href="https://github.com/kmeng01/memit"
                  >Code</a
                >
                |
                <a
                  class="box-in demo"
                  href="https://memit.baulab.info/"
                  target="_blank"
                  >Project Page</a
                >
                <br />
                <i> <span style="font-weight: bold">Kevin Meng</span>, </i>
                Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, David Bau
                <br />
                <i>*To appear at ICLR 2023 in Kigali, Rwanda</i>
              </p>
              <p style="text-align: justify">
                Recent work has shown exciting promise in updating large
                language models with new memories, so as to replace obsolete
                information or add specialized knowledge. However, this line of
                work is predominantly limited to updating single associations.
                We develop MEMIT, a method for directly updating a language
                model with many memories, demonstrating experimentally that it
                can scale up to thousands of associations for GPT-J (6B) and
                GPT-NeoX (20B), exceeding prior work by orders of magnitude.
              </p>
            </div>
            <div class="col-md-4 my-auto">
              <img
                class="img-fluid thumbnail-img no-border"
                src="./Kevin Meng_files/mrome-architecture-crop.png"
                alt="MEMIT-1"
              />
              <br /><br />
              <img
                class="img-fluid thumbnail-img no-border"
                src="./Kevin Meng_files/mrome-update-crop.png"
                alt="MEMIT-2"
              />
            </div>
          </div>
          <div id="rome" class="row mb-3">
            <div class="col-md-8">
              <h5 style="font-weight: bold">
                Locating and Editing Factual Associations in GPT
              </h5>
              <p>
                <a
                  class="box-in paper"
                  target="_blank"
                  href="https://arxiv.org/abs/2202.05262"
                  >NeurIPS '22</a
                >
                |
                <a
                  class="box-in code"
                  target="_blank"
                  href="https://github.com/kmeng01/rome"
                  >Code</a
                >
                |
                <a
                  class="box-in demo"
                  href="https://rome.baulab.info/"
                  target="_blank"
                  >Project Page</a
                >
                <br />
                <i> <span style="font-weight: bold">Kevin Meng</span>*, </i>
                David Bau*, Alex Andonian, Yonatan Belinkov
                <br />
                <i>*To appear at NeurIPS 2022 in New Orleans, LA</i>
              </p>
              <p style="text-align: justify">
                We investigate the mechanisms underlying factual knowledge
                recall in autoregressive transformer language models. First, we
                develop a causal intervention for identifying neuron activations
                capable of altering a model's factual predictions. Within large
                GPT-style models, this reveals two distinct sets of neurons that
                we hypothesize correspond to knowing an abstract fact and saying
                a concrete word, respectively. This insight inspires the
                development of ROME, a novel method for editing facts stored in
                model weights. For evaluation, we assemble CounterFact, a
                dataset of over twenty thousand counterfactuals and tools to
                facilitate sensitive measurements of knowledge editing. Using
                CounterFact, we confirm the distinction between saying and
                knowing neurons, and we find that ROME achieves state-of-the-art
                performance in knowledge editing compared to other methods. An
                interactive demo notebook, full code implementation, and the
                dataset are available.
              </p>
            </div>
            <div class="col-md-4 my-auto">
              <img
                class="img-fluid thumbnail-img no-border"
                src="./Kevin Meng_files/small-ct-animation.gif"
                alt="VeriClaim Poster"
              />
            </div>
          </div>
          <div id="nhash" class="row mb-3">
            <div class="col-md-8">
              <h5 style="font-weight: bold">
                Studying the Approximate Linearity of Apple's NeuralHash
              </h5>
              <p>
                <a
                  class="box-in paper"
                  target="_blank"
                  href="https://mengk.me/projects/nhash/paper.pdf"
                  >ICML ML4Cyber '22</a
                >
                <br />
                Jagdeep Bhatia*,
                <i><span style="font-weight: bold">Kevin Meng</span>*</i>
                <br />
                <i>*Presented at ICML 2022's ML for Cybersecurity Workshop</i>
              </p>
              <p style="text-align: justify">
                Perceptual hashes map images with identical semantic content to
                the same <i>n</i>-bit hash value, while mapping
                semantically-different images to different hashes. These
                algorithms carry important applications in cybersecurity such as
                copyright infringement detection, content fingerprinting, and
                surveillance. Apple's NeuralHash is one such system that aims to
                detect the presence of illegal content on users' devices without
                compromising consumer privacy. We make the surprising discovery
                that NeuralHash is approximately linear, which inspires the
                development of novel black-box attacks that can (i) evade
                detection of "illegal" images, (ii) generate near-collisions,
                and (iii) leak information about hashed images, all without
                access to model parameters. These vulnerabilities pose serious
                threats to NeuralHash's security goals; to address them, we
                propose a simple fix using classical cryptographic standards.
              </p>
            </div>
            <div class="col-md-4 my-auto">
              <img
                class="img-fluid thumbnail-img"
                src="./Kevin Meng_files/nhash.jpg"
                alt="NeuralHash Project"
              />
            </div>
          </div>
          <div id="vericlaim" class="row mb-3">
            <div class="col-md-8">
              <h5 style="font-weight: bold">
                VeriClaim: End-to-End Computational Fact Checking
              </h5>
              <p>
                <a
                  class="box-in paper"
                  target="_blank"
                  href="https://mengk.me/projects/vericlaim/vericlaim.pdf"
                  >NeurIPS AI4CE '21</a
                >
                |
                <a
                  class="box-in preprint"
                  target="_blank"
                  href="https://mengk.me/#gbat"
                  >Claim-Spotter Paper</a
                >
                |
                <a
                  class="box-in demo"
                  href="https://www.youtube.com/watch?v=3Vsr7vzZSxk"
                  target="_blank"
                  >Demo Video</a
                >
                <br />
                <i>
                  <span style="font-weight: bold">Kevin Meng</span>
                </i>
                <br />
                <i
                  >*Presented at NeurIPS 2021's Workshop on AI for Credible
                  Elections</i
                >
              </p>
              <p style="text-align: justify">
                VeriClaim contains two computational modules: the claim-spotter
                and claim-checker. The claim-spotter first selects
                “check-worthy” factual statements from large amounts of text
                using a Bidirectional Encoder Representations from Transformers
                (BERT) model trained with a novel gradient-based adversarial
                training algorithm. Then, selected factual statements are passed
                to the claim-checker, which employs a separate stance detection
                BERT model to verify each statement using evidence retrieved
                from a multitude of knowledge resources. Web interface inspired
                by <a href="https://fakta.app/" target="_blank">Fakta</a>, from
                MIT.
              </p>
            </div>
            <div class="col-md-4 my-auto">
              <img
                class="img-fluid thumbnail-img"
                src="./Kevin Meng_files/vericlaim_neurips_poster.jpg"
                alt="VeriClaim Poster"
              />
            </div>
          </div>
          <div id="36hrfit" class="row mb-3">
            <div class="col-md-8">
              <h5 style="font-weight: bold">
                36 Hour Fitness: Your Personalized Fitness Trainer
              </h5>
              <p>
                <a
                  class="box-in demo"
                  href="https://www.youtube.com/watch?v=7teEfW1DMPQ"
                  target="_blank"
                  >Demo Video</a
                >
                <br />
                <i
                  ><span style="font-weight: bold">Kevin Meng</span>, Brandon
                  Wang, Nihar Annam, Julia Camacho</i
                >
                <br />
                <i
                  >*HackMIT 2020 Grand Prize Winner, DRW Special Award Winner</i
                >
              </p>
              <p style="text-align: justify">
                In light of heightened obstacles to human interaction and
                physical health due to COVID-19, we present 36 Hour Fitness: a
                fun, intuitive, and powerful app that enhances the quality of
                home workouts while bringing friends, family, and workout
                buddies together over the Internet. This system (built in 36
                hours 😉) helps replicate the gym experience by allowing users
                to select any of their favorite workout videos and receive
                real-time automated feedback. Using gamification and other
                social features, 36 Hour Fitness creates exciting virtual group
                workouts from the comfort of your home. Dynamic time warping,
                neural pose estimation, and simple geometrical formulas are used
                to generate scores and suggestions.
              </p>
            </div>
            <div class="col-md-4 my-auto">
              <div class="embed-responsive embed-responsive-16by9">
                <iframe
                  class="embed-responsive-item"
                  src="./Kevin Meng_files/7teEfW1DMPQ.html"
                  allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen=""
                ></iframe>
              </div>
            </div>
          </div>
          <div id="covid-dash" class="row mb-3 sect">
            <div class="col-md-8">
              <h5 style="font-weight: bold">
                An NLP-Powered Dashboard for Mitigating the COVID-19 Infodemic
              </h5>
              <p>
                <a
                  class="box-in paper"
                  target="_blank"
                  href="https://www.aclweb.org/anthology/2021.eacl-demos.12/"
                  >EACL '21</a
                >
                |
                <a
                  class="box-in code"
                  target="_blank"
                  href="https://github.com/idirlab/covid19"
                  >Code</a
                >
                |
                <a
                  class="box-in code"
                  target="_blank"
                  href="https://github.com/idirlab/covid19data"
                  >Data</a
                >
                |
                <a
                  class="box-in website"
                  href="https://idir.uta.edu/covid-19/"
                  target="_blank"
                  >Dashboard</a
                >
                |
                <a
                  class="box-in demo"
                  href="https://www.youtube.com/watch?v=crLzmuisNBo"
                  target="_blank"
                  >Demo Video</a
                >
                <br />
                <i
                  >Zhengyuan Zhu,
                  <span style="font-weight: bold">Kevin Meng</span>, Josue
                  Caraballo, Israa Jaradat, Xiao Shi, Zeyu Zhang, Farahnaz
                  Akrami, Haojin Liao, Fatma Arslan, Damian Jimenez, Mohammed
                  Samiul Saeef, Paras Pathak, Chengkai Li</i
                >
              </p>
              <p style="text-align: justify">
                This paper introduces a public dashboard which, in addition to
                displaying case counts in an interactive map and a navigational
                panel, also provides some unique features not found in other
                places. Particularly, the dashboard uses a curated catalog of
                COVID-19 related facts and debunks of misinformation, and it
                displays the most prevalent information from the catalog among
                Twitter users in user-selected U.S. geographic regions. We also
                explore the usage of BERT models to match tweets with
                misinformation debunks and detect their stances. We also discuss
                the results of preliminary experiments on analyzing the
                spatio-temporal spread of misinformation.
              </p>
            </div>
            <div class="col-md-4 my-auto">
              <div class="embed-responsive embed-responsive-16by9">
                <iframe
                  class="embed-responsive-item"
                  src="./Kevin Meng_files/crLzmuisNBo.html"
                  allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen=""
                ></iframe>
              </div>
            </div>
          </div>
          <div id="gbat" class="row mb-3">
            <div class="col-md-8">
              <h5 style="font-weight: bold">
                Gradient-Based Adversarial Training on Transformer Networks
              </h5>
              <p>
                <a
                  class="box-in preprint"
                  target="_blank"
                  href="https://arxiv.org/abs/2002.07725"
                  >Pre-Print Paper</a
                >
                |
                <a
                  class="box-in code"
                  target="_blank"
                  href="https://github.com/idirlab/claimspotter"
                  >Code</a
                >
                |
                <a
                  class="box-in website"
                  href="https://idir.uta.edu/claimbuster/"
                  target="_blank"
                  >ClaimBuster Website</a
                >
                <br />
                <i
                  ><span style="font-weight: bold">Kevin Meng</span>*, Damian
                  Jimenez*, Fatma Arslan, Jacob Daniel Devasier, Daniel Obembe,
                  Chengkai Li</i
                >
                <br />
                <i
                  >*Deployed on
                  <a href="https://idir.uta.edu/claimbuster" target="_blank"
                    >ClaimBuster</a
                  >, used by thousands of fact-checkers and research groups
                  worldwide</i
                >
              </p>
              <p style="text-align: justify">
                We introduce the first adversarially-regularized,
                transformer-based claim spotting model that achieves
                state-of-the-art results by a 4.70 point F1-score margin over
                current approaches on the ClaimBuster Dataset. In the process,
                we propose a method to apply adversarial training to transformer
                models, which has the potential to be generalized to many
                similar text classification tasks. Along with our results, we
                are releasing our codebase and manually labeled datasets. We
                also showcase our models' real world usage via a live public
                API.
              </p>
            </div>
            <div class="col-md-4 my-auto">
              <img
                class="img-fluid thumbnail-img"
                src="./Kevin Meng_files/model-arch.png"
                alt="Model Architecture"
              />
            </div>
          </div>
        </div>
      </div>
    </div>
    <footer class="footer bg-info py-4">
      <div class="container">
        <div class="row my-auto">
          <div class="col-md-12 my-auto">
            <h6 style="color: white; text-align: center" class="mb-0">
              website designed and built by kevin meng. last updated jan 2023.
            </h6>
          </div>
        </div>
      </div>
    </footer>
    <script src="./Kevin Meng_files/jquery-3.2.1.min.js.download"></script>
    <script
      src="./Kevin Meng_files/popper.min.js.download"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"
    ></script>
    <script
      src="./Kevin Meng_files/bootstrap.min.js.download"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"
    ></script>
    <script>
      const $navbar = $(".navbar");

      const scrollToElement = (curEl) => {
        console.log(curEl);
        const scrollTop =
          $(curEl).position().top +
          $(curEl).parents().position().top -
          $navbar.outerHeight();

        $("html, body").animate({ scrollTop });
      };

      const interceptHashURL = () => {
        let url = $(location).attr("href");
        if (url.includes("#")) {
          const elName = url.split("#")[1];
          console.log("moving to " + elName);
          scrollToElement("#" + elName);
        }
      };

      $('a[href^="#"]').on("click", function (e) {
        e.preventDefault();
        const curEl = $(this).attr("href");
        scrollToElement(curEl);
      });

      $(window).on("hashchange", interceptHashURL);
      $(document).ready(interceptHashURL);
    </script>
  </body>
</html>
